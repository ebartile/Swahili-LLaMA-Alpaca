[**Swahili**](./README_SW.md) | [**üåêEnglish**](./README.md) | [**üìñNyaraka/Docs**](https://github.com/ebartile/Swahili-LLaMA-Alpaca/wiki) | [**‚ùìMambo/Issues**](https://github.com/ebartile/Swahili-LLaMA-Alpaca/issues) | [**üí¨Majadiliano/Discussions**](https://github.com/ebartile/Swahili-LLaMA-Alpaca/discussions)

<p align="center">
    <img alt="GitHub" src="https://img.shields.io/github/license/ebartile/Swahili-LLaMA-Alpaca.svg?color=blue&style=flat-square">
    <img alt="GitHub release (latest by date)" src="https://img.shields.io/github/v/release/ebartile/Swahili-LLaMA-Alpaca">
    <img alt="GitHub top language" src="https://img.shields.io/github/languages/top/ebartile/Swahili-LLaMA-Alpaca">
    <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/ebartile/Swahili-LLaMA-Alpaca">
    <a href="https://app.codacy.com/gh/ebartile/Swahili-LLaMA-Alpaca/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade"><img src="https://app.codacy.com/project/badge/Grade/5c0c3e40251b4b4d9ce59250bcb8c8aa"/></a>
</p>

To promote open research of large models in the African NLP community, this project has open-sourced the **Swahil LLaMA model and the Alpaca large model with instruction fine-tuning**. These models expand the Swahil vocabulary based on the original LLaMA and use Swahil data for secondary pre-training, further enhancing Swahil basic semantic understanding. Additionally, the project uses Swahil instruction data for fine-tuning on the basis of the Swahil LLaMA, significantly improving the model's understanding and execution of instructions.

**Note:** The project implementation began on 23nd April, 2024. Please bearer with me as i bring it to life. Feel free to email me at ebartile@gmail.com

## Limitations

Although the model in this project may significantly improved Swahil understanding and generation capabilities compared to the original LLaMA and Alpaca, there are also the following limitations:

- It may produce unpredictable harmful content and content that does not conform to human preferences and values.
- Due to computing power and data issues, the training of the related models may not be sufficient, and the Swahil understanding ability needs to be further improved.
- There is no online interactive demo available for now (Note: users will still be able to deploy it locally themselves).

## Citation

Special Thanks to this paper: https://arxiv.org/abs/2304.08177


# Acknowledgements

This project is based on the following open-source projects for secondary development, and we would like to express our gratitude to the related projects and research and development personnel.

|                   Foundation Models, Codes                   |             Quantization, Inference, Deployment              |                             Data                             |                             Code Reference                             |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| [LLaMA by Facebook](https://github.com/facebookresearch/llama)<br/>[Alpaca by Stanford](https://github.com/tatsu-lab/stanford_alpaca)<br/>[alpaca-lora by @tloen](https://github.com/tloen/alpaca-lora) | [llama.cpp by @ggerganov](https://github.com/ggerganov/llama.cpp)<br/>[LlamaChat by @alexrozanski](https://github.com/alexrozanski/LlamaChat)<br/>[text-generation-webui by @oobabooga](https://github.com/oobabooga/text-generation-webui) | [pCLUE and translation data by @brightmart](https://github.com/brightmart/nlp_chinese_corpus)<br/>[oasst1 by OpenAssistant](https://huggingface.co/datasets/OpenAssistant/oasst1) | [Chinese LLaMA model and the Alpaca LLM](https://github.com/ymcui/Chinese-LLaMA-Alpaca/)<br/>[By Yiming Cui](https://github.com/ymcui) |

## Disclaimer

**The resources related to this project are for academic research purposes only and are strictly prohibited for commercial use.** When using parts involving third-party code, please strictly follow the corresponding open-source agreements. The content generated by the model is affected by factors such as model calculation, randomness, and quantization accuracy loss. This project cannot guarantee its accuracy. For any content output by the model, this project does not assume any legal responsibility and does not assume responsibility for any losses that may result from the use of related resources and output results.

This project is initiated and maintained by individuals and collaborators in their spare time, so we cannot guarantee a timely response to resolving relevant issues.

## Feedback

If you have any questions, please submit them in GitHub Issues.

- Before submitting a question, please check if the FAQ can solve the problem and consult past issues to see if they can help.
- Please use our dedicated issue template for submitting.
- Duplicate and unrelated issues will be handled by [stable-bot](https://github.com/marketplace/stale); please understand.
- Raise questions politely and help build a harmonious discussion community.